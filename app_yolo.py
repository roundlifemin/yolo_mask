import os
os.environ["YOLO_CONFIG_DIR"] = "/tmp/Ultralytics"  # ì“°ê¸° ê°€ëŠ¥í•œ ê²½ë¡œ

import streamlit as st
from ultralytics import YOLO
import cv2
import tempfile
import numpy as np

# ë¸Œë¼ìš°ì € ì›¹ìº ìš©
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode
import av  # streamlit-webrtcê°€ ì‚¬ìš©í•˜ëŠ” ì˜ìƒ í”„ë ˆì„ íƒ€ì…

st.set_page_config(page_title="YOLOv8 ë§ˆìŠ¤í¬ íƒì§€", layout="centered")
st.title("ğŸ˜· ë§ˆìŠ¤í¬ ì°©ìš© ìƒíƒœ íƒì§€ - YOLOv8")

# ---------------------------
# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìºì‹œ)
# ---------------------------
@st.cache_resource
def load_model():
    # ê°™ì€ ë””ë ‰í† ë¦¬ì— best.pt í•„ìš”
    return YOLO("best.pt")

model = load_model()

# ---------------------------
# ê³µí†µ ì˜µì…˜ (ì‚¬ì´ë“œë°”)
# ---------------------------
st.sidebar.header("ì˜µì…˜")
conf = st.sidebar.slider("Confidence threshold", 0.0, 1.0, 0.25, 0.01)
imgsz = st.sidebar.selectbox("ì´ë¯¸ì§€ í¬ê¸°(imgsz)", [320, 416, 512, 640, 800], index=3)

# ---------------------------
# ì´ë¯¸ì§€ ì¶”ë¡  í•¨ìˆ˜
# (RGB ì…ë ¥ -> Annotated RGB ë°˜í™˜)
# ---------------------------
def detect_image(image_rgb, conf=0.25, imgsz=640):
    results = model(image_rgb, conf=conf, imgsz=imgsz)   # YOLOv8 ì˜ˆì¸¡
    vis_bgr = results[0].plot()                          # BGR(ì£¼ì„ í¬í•¨)
    vis_rgb = cv2.cvtColor(vis_bgr, cv2.COLOR_BGR2RGB)   # ìŠ¤íŠ¸ë¦¼ë¦¿ í‘œì‹œì— ë§ê²Œ RGBë¡œ
    return vis_rgb

# ---------------------------
# ë¸Œë¼ìš°ì € ì›¹ìº ìš© Transformer
# ---------------------------
class YoloTransformer(VideoTransformerBase):
    def __init__(self, conf=0.25, imgsz=640):
        self.conf = conf
        self.imgsz = imgsz
        self.model = model  # ìºì‹œëœ ëª¨ë¸ ì¬ì‚¬ìš©

    def transform(self, frame: av.VideoFrame):
        img_bgr = frame.to_ndarray(format="bgr24")
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        # YOLO ì¶”ë¡ 
        results = self.model(img_rgb, conf=self.conf, imgsz=self.imgsz)
        vis_bgr = results[0].plot()  # BGRë¡œ ì£¼ì„ ë Œë”ë§

        # streamlit-webrtcëŠ” BGR ndarray ë°˜í™˜ ê°€ëŠ¥
        return vis_bgr

# ---------------------------
# íƒì§€ ëª¨ë“œ ì„ íƒ
# ---------------------------
mode = st.sidebar.radio("íƒì§€ ëª¨ë“œ ì„ íƒ", ["ì´ë¯¸ì§€", "ì›¹ìº (ë¸Œë¼ìš°ì €)", "ë™ì˜ìƒ"])

# ---------------------------
# 1) ì´ë¯¸ì§€
# ---------------------------
if mode == "ì´ë¯¸ì§€":
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        st.image(image_rgb, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
        st.subheader("íƒì§€ ê²°ê³¼")

        result_rgb = detect_image(image_rgb, conf=conf, imgsz=imgsz)
        st.image(result_rgb, caption="íƒì§€ëœ ì´ë¯¸ì§€", use_container_width=True)

# ---------------------------
# 2) ì›¹ìº (ë¸Œë¼ìš°ì €)
# ---------------------------
elif mode == "ì›¹ìº (ë¸Œë¼ìš°ì €)":
    st.info("ë¸Œë¼ìš°ì € ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")
    # í˜„ì¬ ìŠ¬ë¼ì´ë” ê°’ì„ transformerì— ì „ë‹¬í•˜ê¸° ìœ„í•´ factoryë¡œ ì£¼ì…
    webrtc_streamer(
        key="yolo-webrtc",
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={"video": True, "audio": False},
        video_transformer_factory=lambda: YoloTransformer(conf=conf, imgsz=imgsz),
    )

# ---------------------------
# 3) ë™ì˜ìƒ
# ---------------------------
elif mode == "ë™ì˜ìƒ":
    uploaded_video = st.file_uploader("ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.flush()

        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()
        st.subheader("íƒì§€ ê²°ê³¼ (ì‹¤ì‹œê°„ ì¬ìƒ)")

        # ê°„ë‹¨í•œ ì§„í–‰ ë°”
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
        pbar = st.progress(0)
        cur = 0

        while cap.isOpened():
            ret, frame_bgr = cap.read()
            if not ret:
                break

            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
            result_rgb = detect_image(frame_rgb, conf=conf, imgsz=imgsz)
            stframe.image(result_rgb, channels="RGB", use_container_width=True)

            cur += 1
            if total_frames > 0:
                pbar.progress(min(cur / total_frames, 1.0))

        cap.release()
        st.success("ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
