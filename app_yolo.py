# requirements:
# pip install ultralytics streamlit streamlit-webrtc opencv-python-headless av numpy

import os
import cv2
import numpy as np
import tempfile

import streamlit as st
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode
import av  # ì˜ìƒ í”„ë ˆì„ íƒ€ì…

# ğŸ’¡ í™˜ê²½ ì„¤ì •
st.set_page_config(page_title="YOLOv8 ë§ˆìŠ¤í¬ íƒì§€", layout="centered")
st.title("ğŸ˜· ë§ˆìŠ¤í¬ ì°©ìš© ìƒíƒœ íƒì§€ - YOLOv8")

# YOLO ì„¤ì • ë””ë ‰í† ë¦¬ ë³€ê²½ (ê¶Œí•œ ë¬¸ì œ íšŒí”¼)
os.environ["YOLO_CONFIG_DIR"] = "/tmp/Ultralytics"

# ---------------------------
# âœ… YOLO ëª¨ë¸ ë¡œë”© (ìºì‹±)
# ---------------------------
@st.cache_resource
def load_model():
    return YOLO("best.pt")  # ì‚¬ì „ í•™ìŠµëœ ë§ˆìŠ¤í¬ íƒì§€ ëª¨ë¸ í•„ìš”

model = load_model()

# ---------------------------
# âœ… ì‚¬ì´ë“œë°” ì„¤ì •
# ---------------------------
st.sidebar.header("ì˜µì…˜")
conf = st.sidebar.slider("Confidence threshold", 0.0, 1.0, 0.25, 0.01)
imgsz = st.sidebar.selectbox("ì´ë¯¸ì§€ í¬ê¸°(imgsz)", [320, 416, 512, 640, 800], index=3)
mode = st.sidebar.radio("íƒì§€ ëª¨ë“œ ì„ íƒ", ["ì´ë¯¸ì§€", "ì›¹ìº (ë¸Œë¼ìš°ì €)", "ë™ì˜ìƒ"])

# ---------------------------
# âœ… ì´ë¯¸ì§€ ì¶”ë¡  í•¨ìˆ˜
# ---------------------------
def detect_image(image_rgb, conf=0.25, imgsz=640):
    results = model(image_rgb, conf=conf, imgsz=imgsz)
    vis_bgr = results[0].plot()
    vis_rgb = cv2.cvtColor(vis_bgr, cv2.COLOR_BGR2RGB)
    return vis_rgb

# ---------------------------
# âœ… ì›¹ìº ìš© Transformer í´ë˜ìŠ¤
# ---------------------------
class YoloTransformer(VideoTransformerBase):
    def __init__(self, conf=0.25, imgsz=640):
        self.conf = conf
        self.imgsz = imgsz
        self.model = model  # ìºì‹œëœ YOLO ëª¨ë¸ ì‚¬ìš©

    def transform(self, frame: av.VideoFrame):
        img_bgr = frame.to_ndarray(format="bgr24")
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        results = self.model(img_rgb, conf=self.conf, imgsz=self.imgsz)
        vis_bgr = results[0].plot()

        return vis_bgr

# ---------------------------
# âœ… íƒì§€ ëª¨ë“œ: ì´ë¯¸ì§€
# ---------------------------
if mode == "ì´ë¯¸ì§€":
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        st.image(image_rgb, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
        st.subheader("íƒì§€ ê²°ê³¼")

        result_rgb = detect_image(image_rgb, conf=conf, imgsz=imgsz)
        st.image(result_rgb, caption="íƒì§€ëœ ì´ë¯¸ì§€", use_container_width=True)

# ---------------------------
# âœ… íƒì§€ ëª¨ë“œ: ì›¹ìº 
# ---------------------------
elif mode == "ì›¹ìº (ë¸Œë¼ìš°ì €)":
    st.info("ë¸Œë¼ìš°ì € ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")
    webrtc_streamer(
        key="yolo-webrtc",
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={"video": True, "audio": False},
        video_transformer_factory=lambda: YoloTransformer(conf=conf, imgsz=imgsz),
    )

# ---------------------------
# âœ… íƒì§€ ëª¨ë“œ: ë™ì˜ìƒ
# ---------------------------
elif mode == "ë™ì˜ìƒ":
    uploaded_video = st.file_uploader("ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.flush()

        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()
        st.subheader("íƒì§€ ê²°ê³¼ (ì‹¤ì‹œê°„ ì¬ìƒ)")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
        pbar = st.progress(0)
        cur = 0

        while cap.isOpened():
            ret, frame_bgr = cap.read()
            if not ret:
                break

            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
            result_rgb = detect_image(frame_rgb, conf=conf, imgsz=imgsz)
            stframe.image(result_rgb, channels="RGB", use_container_width=True)

            cur += 1
            if total_frames > 0:
                pbar.progress(min(cur / total_frames, 1.0))

        cap.release()
        st.success("ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
